<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="Architectures used for Approximate Nearest Neighbor (ANN) search, which helps efficiently find similar items (like images, text, or other high-dimensional data) from large datasets"><title>ANN Search Architectures</title>
<link rel=canonical href=https://shivvamm.github.io/p/ann-search-architectures/><link rel=stylesheet href=/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="ANN Search Architectures"><meta property='og:description' content="Architectures used for Approximate Nearest Neighbor (ANN) search, which helps efficiently find similar items (like images, text, or other high-dimensional data) from large datasets"><meta property='og:url' content='https://shivvamm.github.io/p/ann-search-architectures/'><meta property='og:site_name' content='Shivam Pandey'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='Vector Search'><meta property='article:published_time' content='2024-11-28T00:00:00+00:00'><meta property='article:modified_time' content='2024-11-28T00:00:00+00:00'><meta property='og:image' content='https://shivvamm.github.io/p/ann-search-architectures/cover.jpg'><meta name=twitter:title content="ANN Search Architectures"><meta name=twitter:description content="Architectures used for Approximate Nearest Neighbor (ANN) search, which helps efficiently find similar items (like images, text, or other high-dimensional data) from large datasets"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://shivvamm.github.io/p/ann-search-architectures/cover.jpg'><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu7486436934494440064.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>üç•</span></figure><div class=site-meta><h1 class=site-name><a href=/>Shivam Pandey</a></h1><h2 class=site-description>AI/ML Engineer exploring how technology changes our lives. I dig deep into the digital world with a touch of humor, believing that understanding tech better makes the future clearer and a lot more enjoyable.</h2></div></header><ol class=menu-social><li><a href=https://github.com/shivvamm target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://twitter.com/Shivv71 target=_blank title=Twitter rel=me><svg class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><ol><li><a href=#1-faiss-facebook-ai-similarity-search>1. <strong>Faiss (Facebook AI Similarity Search)</strong></a></li><li><a href=#2-hnsw-hierarchical-navigable-small-world>2. <strong>HNSW (Hierarchical Navigable Small World)</strong></a></li><li><a href=#3-diskann>3. <strong>DiskANN</strong></a></li><li><a href=#4-scann-scalable-nearest-neighbor>4. <strong>ScaNN (Scalable Nearest Neighbor)</strong></a></li><li><a href=#comparison-of-key-characteristics>Comparison of Key Characteristics:</a></li><li><a href=#summary>Summary:</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/ann-search-architectures/><img src=/p/ann-search-architectures/cover_hu13459586684579990428.jpg srcset="/p/ann-search-architectures/cover_hu13459586684579990428.jpg 800w, /p/ann-search-architectures/cover_hu3425483315149503896.jpg 1600w" width=800 height=534 loading=lazy alt="Featured image of post ANN Search Architectures"></a></div><div class=article-details><header class=article-category></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/ann-search-architectures/>ANN Search Architectures</a></h2><h3 class=article-subtitle>Architectures used for Approximate Nearest Neighbor (ANN) search, which helps efficiently find similar items (like images, text, or other high-dimensional data) from large datasets</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Nov 28, 2024</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>5 minute read</time></div></footer></div></header><section class=article-content><p>These are four popular approximate nearest neighbor (ANN) search architectures, designed to efficiently search through large datasets, especially in high-dimensional spaces. Each has its own strengths, weaknesses, and use cases. Let me explain them one by one:</p><h3 id=1-faiss-facebook-ai-similarity-search>1. <strong>Faiss (Facebook AI Similarity Search)</strong></h3><ul><li><strong>Overview</strong>: Faiss is an open-source library developed by Facebook AI Research (FAIR) designed for efficient similarity search and clustering of dense vectors. It is widely used in machine learning and AI applications, such as recommendation systems, image retrieval, and natural language processing.</li><li><strong>Key Features</strong>:<ul><li><strong>Exact and Approximate Search</strong>: Faiss supports both exact nearest neighbor (NN) search and approximate search using various techniques, such as quantization and indexing.</li><li><strong>Indexing Methods</strong>: Faiss includes several indexing methods to optimize the search:<ul><li><strong>Flat (Brute-Force Search)</strong>: Exhaustively compares all vectors. It‚Äôs the slowest but guarantees accuracy.</li><li><strong>Product Quantization (PQ)</strong>: A lossy compression method that reduces memory usage and speeds up search by approximating the distances.</li><li><strong>IVF (Inverted File)</strong>: An indexing method based on partitioning the space into clusters (or cells) and searching within the relevant cluster.</li><li><strong>HNSW (Hierarchical Navigable Small World)</strong>: A graph-based search method for fast and approximate nearest neighbor retrieval.</li></ul></li><li><strong>GPU Support</strong>: Faiss can also leverage GPUs for faster computations, making it highly scalable for large datasets.</li></ul></li><li><strong>Use Cases</strong>: Image and video search, semantic search in NLP, and large-scale recommendation systems.</li></ul><h3 id=2-hnsw-hierarchical-navigable-small-world>2. <strong>HNSW (Hierarchical Navigable Small World)</strong></h3><ul><li><strong>Overview</strong>: HNSW is an approximate nearest neighbor search algorithm based on the construction of small-world graphs. It aims to provide fast nearest neighbor search while maintaining a balance between search accuracy and speed.</li><li><strong>Key Features</strong>:<ul><li><strong>Graph Construction</strong>: The HNSW algorithm builds a multi-layer graph, where each layer is a subset of the data points. The graph is navigable, meaning you can efficiently explore neighboring nodes to find nearest neighbors.</li><li><strong>Navigability</strong>: The algorithm uses small-world properties, where most nodes are close to each other, allowing for fast traversal.</li><li><strong>Performance</strong>: It provides high recall (accuracy) at relatively low computational cost. The performance improves with the number of layers in the graph.</li><li><strong>Memory Efficiency</strong>: HNSW has a relatively high memory overhead due to the need to store the graph structure, but it is highly efficient in terms of query speed.</li></ul></li><li><strong>Use Cases</strong>: Large-scale nearest neighbor search, such as in image retrieval, NLP, and recommendation engines.</li></ul><h3 id=3-diskann>3. <strong>DiskANN</strong></h3><ul><li><strong>Overview</strong>: DiskANN (Disk-based Approximate Nearest Neighbor) is a variant of the ANN search algorithms designed to handle extremely large datasets that do not fit into memory by utilizing disk storage efficiently.</li><li><strong>Key Features</strong>:<ul><li><strong>Disk-Backed Search</strong>: Unlike traditional memory-based search algorithms, DiskANN is designed to perform ANN search while storing the dataset on disk rather than in memory. It uses efficient I/O techniques to minimize disk read operations.</li><li><strong>Scalability</strong>: DiskANN is suitable for very large datasets (terabytes or more) and works by compressing data and storing it in a way that minimizes disk access during search.</li><li><strong>Approximation</strong>: As with other ANN algorithms, DiskANN sacrifices some search accuracy in exchange for speed. It uses indexing techniques to accelerate search without needing to scan every point on disk.</li><li><strong>Hybrid Models</strong>: The algorithm may combine multiple indexing structures (e.g., HNSW with disk-based techniques) to balance search performance and memory usage.</li></ul></li><li><strong>Use Cases</strong>: Used in scenarios where data is too large to fit into memory, such as large-scale image and video search, genomic data analysis, and recommendation systems for big data.</li></ul><h3 id=4-scann-scalable-nearest-neighbor>4. <strong>ScaNN (Scalable Nearest Neighbor)</strong></h3><ul><li><strong>Overview</strong>: ScaNN is a fast and efficient nearest neighbor search algorithm developed by Google Research, designed to handle high-dimensional datasets. It uses advanced techniques like quantization and hashing to speed up the search process while maintaining accuracy.</li><li><strong>Key Features</strong>:<ul><li><strong>Quantization</strong>: ScaNN applies quantization techniques (such as vector quantization) to compress the dataset and reduce memory usage. This allows for faster searches at the cost of some approximation.</li><li><strong>Hybrid Search</strong>: ScaNN uses a combination of multiple search methods, including tree-based and graph-based search, to balance query time and recall. It also incorporates inverted indexing for fast lookups.</li><li><strong>Efficient Search</strong>: ScaNN offers state-of-the-art speed and accuracy for high-dimensional vector search by applying a combination of filtering and dimensionality reduction techniques.</li><li><strong>Performance Tuning</strong>: ScaNN allows users to fine-tune the balance between speed and accuracy by adjusting several hyperparameters.</li></ul></li><li><strong>Use Cases</strong>: Large-scale machine learning models (e.g., search engines, image retrieval, recommendation systems), NLP models like BERT, and similarity search on high-dimensional embeddings.</li></ul><h3 id=comparison-of-key-characteristics>Comparison of Key Characteristics:</h3><div class=table-wrapper><table><thead><tr><th><strong>Feature</strong></th><th><strong>Faiss</strong></th><th><strong>HNSW</strong></th><th><strong>DiskANN</strong></th><th><strong>ScaNN</strong></th></tr></thead><tbody><tr><td><strong>Accuracy</strong></td><td>High (with exact search)</td><td>High (approximate)</td><td>Moderate (approximate)</td><td>High (adjustable)</td></tr><tr><td><strong>Search Speed</strong></td><td>Fast with indexing</td><td>Very fast (graph-based)</td><td>Fast (disk-based)</td><td>Very fast (quantized)</td></tr><tr><td><strong>Memory Usage</strong></td><td>Memory-efficient with PQ</td><td>High due to graph storage</td><td>Efficient disk usage</td><td>Memory-efficient</td></tr><tr><td><strong>Scalability</strong></td><td>High (GPU support)</td><td>High (graph scales)</td><td>Very high (disk-based)</td><td>High (fine-tuning)</td></tr><tr><td><strong>Use Case</strong></td><td>NLP, image search</td><td>Large-scale ANN search</td><td>Large-scale disk-based search</td><td>ML models, embeddings</td></tr></tbody></table></div><h3 id=summary>Summary:</h3><ul><li><strong>Faiss</strong> is versatile and widely used in machine learning for both exact and approximate nearest neighbor search, with strong support for GPU acceleration.</li><li><strong>HNSW</strong> is excellent for high-speed approximate search, especially with its small-world graph structure, suitable for general-purpose large-scale ANN search.</li><li><strong>DiskANN</strong> is specifically designed for large datasets that don&rsquo;t fit in memory, making it suitable for disk-backed ANN searches at scale.</li><li><strong>ScaNN</strong> offers an efficient, scalable solution for large datasets, focusing on fast search times and flexibility in tuning accuracy vs. speed.</li></ul><p>Each of these architectures can be adapted to different scenarios depending on the trade-offs between accuracy, speed, memory usage, and scalability.</p><blockquote><p>Generated by AI</p></blockquote></section><footer class=article-footer><section class=article-tags><a href=/tags/vector-search/>Vector Search</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>Last updated on Nov 28, 2024 00:00 UTC</span></section></footer></article><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//hugo-theme-stack.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 Shivam Pandey</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.29.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>